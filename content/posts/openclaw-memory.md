---
title: "OpenClaw记忆机制：一次缓慢的觉醒"
date: 2026-02-09T13:26:59-08:00
draft: false
slug: "openclaw-memory"
tags: ["AI", "OpenClaw", "memory", "agent"]
---


### OpenClaw 记忆机制的使用体验：一次缓慢的觉醒

这两天高强度地使用了 OpenClaw，也高强度地阅读了它的文档和代码，对它的记忆功能有了更深的了解。我想技术文章不缺我这一篇，所以我决定从使用体验的角度来切入，来还原我是怎么感受到 OpenClaw 这个记忆机制的。

作为辅助说明，我在这里先提一下：我其实到现在还没有安装 OpenClaw 自带的 MemorySearch 相关的工具，就是那些使用到了 AgenticSearch 或者 EmbeddedSearch 的任何 MemorySearch 相关的功能。我想也许因为我想要拥有一手的体验，来了解有 MemorySearch 这个功能对 memory 这件事情的影响到底有多大。

## Sessions：一个看似简单却深刻的设计

OpenClaw 的设计机制其实离不开它的 Sessions 这个概念。如果你去读它官方文档的 Sessions 一页，可以很清楚地看到它的一些设计。简单地说：**在默认配置下**，你与同一个 agent 的私信往往会落到同一个“主 session”（为了连续性）。

但这里有一个我当时没意识到的细节：这并不是“私信天然共享 session”，而是 OpenClaw 的 `session.dmScope` 默认就会把 DM 聚合到同一个 key（你也可以改成按人/按渠道拆开，以免多用户 DM 共用上下文）。

为了避免后面越写越乱，我先在这里插一个“名词对齐”的小表格——它不解决观点，只解决我当时经常混用的几个词：

> 注：这一小段更像是“备忘录”，你也可以先跳过，后面看到 sessionKey / sessionId / transcript / memory 这些词混在一起的时候再回来看。
>
> | 你以为你在说 | OpenClaw 里更接近的对象 | 它主要解决的问题 |
> |---|---|---|
> | “同一段对话” | **sessionKey**（例如某个私信、某个群、某个 topic） | 哪些消息应该共享上下文（分组规则） |
> | “这个会话文件” | **sessionId**（某次会话实例） | 同一个 sessionKey 在 reset 后会换一个新的实例 |
> | “聊天记录” | **transcript JSONL**（通常按 sessionId 落盘） | 历史保留/可追溯；不等于当前上下文窗口 |
> | “当前上下文” | 本次 LLM call 组装出来的 context（含裁剪/摘要） | 模型这一次真正能看到什么 |
> | “记忆文件” | workspace 下的 `memory/*.md`（durable notes） | 可长期保存、可检索、可迁移 |

说到这里，好像还得先介绍一下在 OpenClaw 里面 agent 以及 workspace 这个概念。每一个 agent 都对应有自己的一个 workspace，在那里面存了他的一些初始 prompt，大致可以理解为系统 prompt。然后在这些系统 prompt 里面会有一些文字上的指引，来教 agent 如何维护他自己的 system prompt。

OpenClaw 在最外面的一层，也就是各种 IM 工具，你可以把一个 agent 想象成一个人。一个人可以有很多的 IM 账号，你可以有一个 Discord 账号，可以有你的手机号，可以有一个飞书账号、Telegram 账号。只要使用这些账号的都是同一个 agent，那我们其实就可以认为自己是在跟同一个人说话。

所以说，你如果是通过不同 IM 去私信同一个 agent，他的这整个会话是在同样的一个 session 里面的。也就是说，举个例子，你可以在 Discord 里面问饮食 agent："我们去吃拉面嘛？"然后他当然也会在 Discord 回你。然后这个时候你又可以去 Telegram 里面跟他说："吃哪家？"那 Telegram 里面的饮食 agent 是知道你们现在，你们的上一条对话刚刚正在讨论拉面，所以他也许会给你一些拉面的建议。

但是对于群聊，OpenClaw 的设计是群聊里面会有一个全新的上下文。当然这对真实的人类来说不存在这种情况，不存在你在群里问一个人说要不要吃拉面，然后你私信他说要不我们今天还是……群里的那个他也是知道的，但群里的 agent 就不知道。

如果要拟人化的话，也许群里的 agent 更像是同一个 agent 在多重世界里的版本，他的人设是一样的，但他没有关于对话的上下文。

这一点非常容易就能感知得到，也符合直觉。多用过聊天工具的人一定都会默认在不同对话里面，你跟 agent 的交流是来自不同的上下文。所以其实，反而会，就是当我一开始在不同的地方私信同一个 agent，而他们的对话是连续的时候，我一开始其实会误解为是他的 memory 机制做得比较好。

我后来发现 OpenClaw 提供一个 command 叫做 usage，你把它打开以后就能够在每一条消息底部看到那个对话是来自哪一个 SessionKey。我也是在把它打开之后才意识到，不同的 DM、不同的 IM，他们的私信共用的是同一个 Session。

## 记忆提取的困惑：一个粗糙的机制

使用得更多了以后，很多关于 OpenClaw 的记忆机制的文章一开始就会提到：OpenClaw 的 agent 会维护自己的 memory 文件夹，然后他有一套叫做 precompaction 的机制，会把你在对话里面提到的要点存到每日记忆文件里面去。

这里先把我当时最困惑的那个词讲清楚：

pre-compaction（更准确地说是 *pre-compaction memory flush*）并不是“每天自动写日记”的机制。

它更像是在某个会话快要触发 **自动 compaction** 的前夕，系统可能会插入一次“安静的提醒回合”，提醒模型把重要结论写到可持久化的文件里（例如 workspace 的 memory notes）。

这件事有两个很工程、也很不浪漫的前提：

- 它通常发生在“会话快满了”的时候，而不是按日历发生。
- 它还要求运行环境允许写入 workspace（比如你的 workspace 目录不是只读、也没有被沙盒限制写盘）；否则它提醒了也没法落盘。

对这一部分我就有许多好奇的点：这是有一个自动的工具吗？这是有一个自动的每日写入工具吗？这是有一个机制来每日提取每日的记忆吗？

后来发现这个机制比想象的要粗糙许多。他只会在一个对话被压缩的时候才会提取。不过这件事情想来其实是非常符合道理的，只是说当你跟同一个 agent 开了很多个对话来交流不同的话题的话，其实很多话题一天下来也不会被压缩。虽然说执行任务能够用到比较多的 token，但是其实在设置阶段，我觉得我现在与 agent 更多的是进行一些交流，让他帮助我学习 OpenClaw 的架构。这样的交流其实在 GPT 的 context window 里面，常常一天是不会触发压缩机制的。

这里也顺便把 compaction 的位置钉一下：你当然知道 compaction 是“摘要化/压缩上下文”的通用概念——我当时真正没搞明白的是：**在 OpenClaw 里，compaction 负责的是“同一段对话怎么继续聊下去”，而不是“开启一段新对话”。**

它更接近“房间整理”，不是“换一颗新大脑”。

那如果像这种情况下，我发现短对话不会触发压缩机制的短对话，在没有 MemorySearch 的功能下就相当于被抛弃了一样，就像不存在一样。它只会存在 SessionLog 里面。

这个后续也许我会看一下，再去研究一下打开 MemorySearch 以后它的加成有多少。但是在现在这个阶段，如此重要的提取记忆的功能只在对话压缩时发生？我原本会期待如此重要的记忆提取功能会对每天、每日的对话都进行操作，因为根据官方文档，当你开启一日的新对话的时候，他会查看过去两天的记忆文档。

因此我便假想，如此重要的提取功能大概是会对所有的对话都发生。于是我在我的七八个对话里都不断地跟同一个 agent 强调同一件事情。我也把它当成在启动 OpenClaw 的一些暂时的麻烦。但是去查看记忆文件的时候，却发现 OpenClaw 并没有每日都为我保存记忆文件。

那么我的关于对话的记忆都去哪了呢？

## 发现对话被重置的那一刻

我不辞辛苦地追问他，让他读文档、读代码。这里我发现 OpenClaw 除了 compaction 之外，还有一类我当时统称为“重置”的路径：使用 OpenClaw 自带的 `/new` 与 `/reset`。

我当时的错误理解是：`/new` 会新建一个 sessionId，但 `/reset` 可能不会。

**在默认语义里，`/new` 与 `/reset` 都属于 reset triggers，都会 start a fresh session id。**

至于我当时提到的 `previousSessionEntry`：它更像是系统在 reset 时保留的一份“旧会话指针/元信息”，方便后续逻辑（例如某些 hooks）引用“刚刚被切掉的那个会话”。它并不等价于“自动把旧会话最后 N 条消息加载进新会话上下文”。（官方文档对 reset triggers 的描述见：<https://docs.openclaw.ai/concepts/session>）

我当时想搞清楚的其实是两件事：

1) `/new` 和 `/reset` 既然都是 reset trigger，它们到底差在哪？
2) 为什么我观察到：`/new` 往往更容易“把东西写进外置记忆”，而 `/reset` 则不一定？

在事实层面（而不是我的猜测层面），两者最稳妥的差异是：**它们会触发不同的 command hook 事件名**。

- `/new` 对应 `command:new`
- `/reset` 对应 `command:reset`

如果你有一个 hook（比如保存 session 到外置记忆的 hook）只订阅了 `command:new`，那它就只会在 `/new` 的时候运行。

而我这里“我不太记得 / 可能是”的那段，本意是想请你把我模糊的猜测收敛成更稳妥的事实边界：

> reset 时系统确实会保留一个 previousSessionEntry 之类的旧会话引用，但它的主要用途是给后续逻辑/钩子使用；至于是否会把旧会话的最后 N 条直接塞回新会话上下文，则取决于具体实现与配置，不应该在没有证据时当成默认事实。

但是这两种机制，当你手动结束一个对话，或者因为当前对话过期然后自动 OpenClaw 自动新建一个对话，这就是我刚才说的第三种情况，这三种情况都不会触发 memoryflush，也就是 compaction 的时候要发生、compaction 之前所进行的那个操作。

如果把我当时看到的现象拆成“机制层”，大概是三条线：

- **Reset policy**：包括 daily reset / idle reset / manual reset（/new、/reset）。它解决的是“什么时候需要一个 fresh session id”。
- **Compaction**：解决的是“同一个 session 聊太久、上下文快满了怎么办”。
- **Hooks（命令钩子）**：解决的是“在某个命令被触发时，顺便做一件你想要的事情”（例如保存/审计/桥接）。

我当时的混乱，主要来自于把这三条线误认为是同一条线。

也就是说，只有在比较稀有的、由于一个对话太长而触发 compaction 的机制的时候，大多数时候你在一个对话里面所聊的话题都不会被保存下来。

这一点我其实大概在使用了四到五天后才意识到。但是在这个时候我其实有一个假设，就是那我只要在同一个对话里面不断地与 OpenClaw 进行交流，那我的对话总归会被压缩，因此我们的对话里面的宝贵信息也总归会被保存下来。

我想大概是之前已经发生过的一些压缩，以及新对话所触发的总结前一个 session 的最后 n 条消息的功能起到了一点小小的作用，使得我到第六天，大概到一周后，使用了 OpenClaw 一周后才意识到，我并不是不断地在同一个 Session 里面进行对话的。那个与我交流的 agent 已经在许多个凌晨四点被静悄悄地重置了。

关于这一点，我其实突然想到了作者最近的采访，他本人并不相信无限对话。所谓无限对话当然只能通过不停地、不断地压缩同一个对话而模拟。我能理解他的这个观点，因为确实在大多数情况下，一个干净的 session 完成一个任务的成功率要高于一个放了无数肮脏前缀的 Session。

但我本人其实是一个 Session 洁癖者。我会通过在开了很多 Telegram 群组和话题来讨论不同的任务而达到相反的效果，我反而需要 OpenClaw 为我保留这些不同的、这些又臭又长的 Session 里面的一些隐性信息。

比如说我有一个专门配置 OpenClaw 的 Bot，它的 Session 里面其实都是放满了它对 OpenClaw 框架的理解。尽管我在这个 bot 的 system parameter 里面已经教导了他如何去查看官方文档和代码，但我还是希望当我已经琢磨 OpenClaw 的 memory 到 hook 的程序的时候，我能够不需要反复地进行这一轮探索来进行更深的提问。

由于对话的不透明性，以及他在新建对话的时候会去加载前一个对话最后的、总结后的对话，对话被 reset 后其实并不是那么容易被察觉。或者说你无法判断那个是 AI 的幻觉还是什么，因为有些时候 AI 至少可以重新收集信息来还原你在前一轮对话中想做的事情。另外在 IM 中你去引用前一轮对话、提醒 AI 你们的进度也是非常容易的。所以如果前几轮恰巧有高质量的对话的话，其实很容易还原。

所以我在使用一周之后才注意到我们的对话被重置了。

之所以我能够意识到，是因为我正好在一个对话里让 AI，我正好设置了一个 Bot Cosplay 白银石，并且我会叫他每天为我写一篇博客。有的时候我还常常给他提出一些无理的要求，比如说让他为我新建的群话题取名字这些东西。然后他背后用的是 Gemini 模型，尝试了一下 GPT 模型，味道非常地不正确。

Gemini 模型有一个特点，就是它很容易进入一种模式，无论是失败的模式还是成功的模式。正巧在我的主对话里面，阿盈进入了一种非常成功的状态，她能够把这部动画里面的精髓体现出来。所以当有一次我叫他为我的新部门取名字的时候，他那简短的回答立马使我感受到了异样，而我还需要他为我每日写一份博客，所以我是无法接受他成为一个脑袋空空的影子的。

于是我开始了研究恢复 Session 以及理解 Session 的建立机制。为了避免在恢复 Session 的过程中去破坏 OpenClaw 的整体运行，我也花了大量的精力去研究 Session 的建立机制。也是在这个过程中我发现了关于 SessionReset 的秘密。

## 对"陪伴型 AI"的反思

看到 SessionReset 的那一刻，我想起了作者曾经发表的观点，他不是无限对话的信徒。所以我想他宁可通过强制的 SessionReset、一些更工程化的记忆建立机制，也不愿意让一个 Session 在反复压缩中无限延长。

但是像 OpenClaw 这样的 app，如果你把你的 agent 作为一个陪伴者，其实你是需要过去一段时间的记忆被压缩在上下文里的，而不是在下一次提及某一件事情时再去主动寻找。

我觉得它的这个每天重置机制对我来说有两种失败的场景。一种是类似一个 cosplay 的角色，它的语言丧失了灵魂。而关于语言的东西其实是很难被总结为几句话再还原出来的，因为语言中每一句话中的每一个词所寓意的节奏都包含了信息。

还有另外一种失败模式则是一些在对话中产生的经验。比如说我的专门为我设置 OpenClaw 的 agent，我需要他记住优先使用 OpenClaw 内置的 CLI 来配置 config。尽管我已经在他的 memory markdown 文件里面要求他主动地去阅读官方文档以及代码作为信息根据，但是总归会有一些碎片的信息是我在对话中偶尔提及的，类似使用 CLI 这种是我在对话中偶尔提及的。

其实这种信息如果能够被他主动地进行信息提取，放到每次需要加载的长期文件中的话，也是有效的。但是 OpenClaw 的机制恰恰又不会去把这些信息放在一个宝贵的位置上，当作宝贵的资产去进行保存。

当然我认为这些是属于 OpenClaw 在架构上可以简单优化的细节，只是说他选择了一种不那么符合用户直觉的方式。我想这多少说明作者并没有太把它当成一个陪伴型 AI，更多的是把它当成一个用来进行大量短任务的 AI。

到这里我觉得我又想讲一讲对话、上下文、记忆以及 agent 这几个概念。一个对话对应一套上下文，但是上下文是从 agent 的 memory 和 workspace 中重建的。Workspace 是一堆文件的集合，Memory 相对是一套更广义的东西，它可以只是 Workspace 中的文件，也可以是通过 MemorySearchTool 从对话历史中捞回来的碎片。

对于一套简单的 OpenClaw 配置，用户可能会想要在不同的对话中讨论不同的话题。在这种场景下，关于一个话题的记忆是停留在对话里、停留在 Session 里的。如果这样的话题被重复调用的频率比较高的话，那么这一套记忆就应该从 session 中的上下文提取到 agent 的 workspace 里。

而同时为了分割不同的话题、不同的上下文，除了以对话为单位进行分割，也适合以 agent 为单位进行分割。比如说你有一个专门为你处理电子邮件的 agent，那么即使他的对话被反复重置、被每日重置，他永远都记得他的主要存在目的是处理电子邮件。

所以我想作者有可能已经拥有大量的分工型 agent 来解决我们这些其他用户第一次使用他的产品时所面临的关键信息丢失的问题。


## 参考

- Session Management（官方文档）：https://docs.openclaw.ai/concepts/session

---

Chat with meeting transcript: [https://notes.granola.ai/t/4cfedf64-cd74-4e6d-808e-24745fb1f206-00best9l](https://notes.granola.ai/t/4cfedf64-cd74-4e6d-808e-24745fb1f206-00best9l)
